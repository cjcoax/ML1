{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you will use `LIME` library to perform local explanations using surrogate modelsto explain the results of Random Forest Classifier models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install LIME library (uncomment plotly installation if needed)\n",
    "#pip install plotly\n",
    "!pip install lime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for data handling, modeling, and visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "# Set random seed for reproducible results\n",
    "np.random.seed(0)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly\n",
    "import matplotlib\n",
    "# Configure default figure size\n",
    "matplotlib.rcParams['figure.figsize'] = [10, 7]\n",
    "\n",
    "# warnings.filterwarnings('ignore')\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "\n",
    "# Load the dataset of songs\n",
    "df_data = pd.read_csv('./music.xls')\n",
    "df_data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1.1: Create the target of popular artists where artist familiarity is greater than 0.8 and artist hotttness is greater than 0.6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create target label based on artist familiarity and hotttness thresholds\n",
    "df_data['class'] = np.where((df_data['artist.familiarity'] > 0.8) & (df_data['artist.hotttnesss'] > 0.6),\n",
    "                           'popular', 'not_popular')\n",
    "\n",
    "# Use GroupBy on class and count artist.id\n",
    "df_data.groupby('class')['artist.id'].count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1.2: Train a Random Forest Classifier with 100 estimators considering these variables:\n",
    "* vars_keep = ['song.bars_confidence', 'song.bars_start', 'song.beats_confidence', 'song.beats_start', 'song.duration', 'song.end_of_fade_in', 'song.hotttnesss', 'song.key_confidence', 'song.loudness', 'song.mode', 'song.mode_confidence', 'song.start_of_fade_out', 'song.tatums_confidence', 'song.tatums_start', 'song.tempo', 'song.time_signature', 'song.time_signature_confidence']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features we will use to train the Random Forest\n",
    "vars_keep = ['song.bars_confidence', 'song.bars_start', 'song.beats_confidence', 'song.beats_start',\n",
    "             'song.duration', 'song.end_of_fade_in', 'song.hotttnesss', 'song.key_confidence',\n",
    "             'song.loudness', 'song.mode', 'song.mode_confidence', 'song.start_of_fade_out',\n",
    "             'song.tatums_confidence', 'song.tatums_start', 'song.tempo', 'song.time_signature',\n",
    "             'song.time_signature_confidence']\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = df_data[vars_keep]\n",
    "y = df_data['class']\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "print('Training set size - X_train: {} '.format(X_train.shape))\n",
    "print('Training set size - X_test: {} '.format(X_test.shape))\n",
    "\n",
    "# RandomForestClassifier n_estimators=100, oob_score=True, random_state=123456\n",
    "rf = RandomForestClassifier(n_estimators=100, oob_score=True, random_state=123456)\n",
    "rf.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2.1: Initializing the LIME explainer. You need to include the following conditions - feature_names, class_names, verbose, discretize_continuous, and mode. It is important to note that when you tune class_name that the order is important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LIME explainer\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "    X_train.values,\n",
    "    feature_names=vars_keep,\n",
    "    class_names=['not_popular', 'popular'],\n",
    "    verbose=True,\n",
    "    discretize_continuous=True,\n",
    "    mode='classification'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assignment, you need to visit the [documentation](https://github.com/marcotcr/lime) for `LIME` and find out how you can pass an instance to get a local explanation and produce some visualizations. Since we are using `LimeTabularExplainer`, you can focus on that in the documentation (example notebooks are provided)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2.2: Choose an instance from the test data, and obtain explanations for it. The explanations should include no more than 5 features (the top 5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose an instance from the test data\n",
    "instance_num = 0\n",
    "\n",
    "# Obtain a local explanation for the instance using up to 5 features\n",
    "local_exp = explainer.explain_instance(X_test.iloc[instance_num], rf.predict_proba, num_features = 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2.3: Produce a feature importance plot for the explanation. HINT: `LIME` has a method for this. You only need to call it. <span style=\"color:red\" float:right>; # you need the semi-colon otherwise two dublicate plots are produced</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce a feature importance plot for the explanation\n",
    "local_exp.as_pyplot_figure();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the explanation as a list of feature contributions\n",
    "local_exp.as_list()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quesiont 3: Call the `show_in_notebook` method to show a summary of the explanation. Set show_table = True, show_all = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show a summary of the explanation inside the notebook\n",
    "local_exp.show_in_notebook(show_table = True, show_all = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 4: Interpret the results shown by calling `show_in_notebook`. Confirm that the predicted probability shown on the left matches the predicted probability we get by calling the model directly on the instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm that the predicted probability matches the model output\n",
    "rf.predict_proba([X_test.iloc[instance_num]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Bonus] Question 5: Repeat the above steps with a Support Vector Machine Classifier. What conclusions to you draw about model explainablity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat the explanation using a Support Vector Machine classifier\n",
    "from sklearn.svm import SVC\n",
    "svm = SVC(probability=True, random_state=123456)\n",
    "svm.fit(X_train, Y_train)\n",
    "svm_exp = explainer.explain_instance(\n",
    "    X_test.iloc[instance_num],\n",
    "    svm.predict_proba,\n",
    "    num_features=5\n",
    ")\n",
    "svm_exp.as_pyplot_figure();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 6: Create a new text cell in your Notebook: Complete a 50-100 word summary (or short description of your thinking in applying this week's learning to the solution) of your experience in this assignment. Include: What was your incoming experience with this model, if any? what steps you took, what obstacles you encountered. how you link this exercise to real-world, machine learning problem-solving. (What steps were missing? What else do you need to learn?) This summary allows your instructor to know how you are doing and allot points for your effort in thinking and planning, and making connections to real-world work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assignment introduced LIME for explaining model predictions. I built a random forest to classify popular songs and explored feature contributions for a specific example. Comparing explanations with a support vector machine highlighted how different models focus on different attributes. Working through the steps clarified how local explanations can increase trust in machine learning results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}