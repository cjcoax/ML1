{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# Assignment 7: Linear Model Selection and Regularization\n",
    "Derived from MLEARN51-Assignment7-Student_Name.ipynb in Canvas MLEARN 510 Spring 2024.   <br>\n",
    "Modified by Ernst Henle. Modifications Copyright Â© 2024 by Ernst Henle<br>\n",
    "<br>\n",
    "## Learning Objectives\n",
    "- Produce a model with l2 regularization, with a statistically significant improvement over a model without regularization.\n",
    "- Produce a model with l1 regularization, with a statistically significant improvement over a model without regularization.\n",
    "- Produce a model with both l1 and l2 regularization terms, with a statistically significant improvement over a model without regularization.\n",
    "- Produce a generalized additive model with a statistically significant improvement over the null model (a model without input variables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code can be removed\n",
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge, LinearRegression, ElasticNet, Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# There could be over 50 Convergence Error Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# our favorite magic\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data and Basic EDA\n",
    "<br>\n",
    "Dataset(s) needed:\n",
    "Kaggle House Prices (https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)<br>\n",
    "\n",
    "This data is only the training data.  We will not use the actual test data in this exercise.  All \"tests\" will be validations done on validation data that is taken from the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/House Prices.csv')\n",
    "print(train.shape)\n",
    "print(train.dtypes.value_counts())\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Question 1.1: Drop the Id column from the data as it is not needed for prediction and may actually lead to overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Original shape: {train.shape}\")\n",
    "train.drop('Id', axis=1, inplace=True)\n",
    "print(f\"Shape after dropping Id: {train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Question 1.2: Visualize a scatter plot of 'GrLivArea' in the x-axis and 'SalePrice' in the y-axis. Can you spot any outliers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.scatterplot(x=train['GrLivArea'], y=train['SalePrice'])\n",
    "plt.title('GrLivArea vs. SalePrice')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion of Ridge Performance vs. Alpha (Question 5.2)**\n",
    "\n",
    "The plot above shows the Root Mean Squared Error (RMSE) for the Ridge model on both the training and validation datasets as the shrinkage parameter `alpha` varies.\n",
    "\n",
    "*   **Estimating the Best Alpha Value:**\n",
    "    Similar to Lasso, the \"best\" alpha value for Ridge is typically found where the validation RMSE is at its minimum. Observing the 'Validation RMSE (Ridge)' line, we look for its lowest point. *[The user will need to visually inspect their generated plot to specify the approximate alpha value here. For example: \"The validation RMSE for Ridge appears to be lowest around an alpha of 1 to 10.\"]*\n",
    "\n",
    "*   **Comparison of Training and Validation Plots:**\n",
    "    - At very low `alpha` values, Ridge behaves similarly to linear regression. Both training and validation RMSE are relatively low.\n",
    "    - As `alpha` increases, the training RMSE for Ridge generally tends to increase, as the regularization penalizes large coefficients, making the model simpler.\n",
    "    - The validation RMSE for Ridge also typically shows a U-shape. It might decrease initially if the model was overfitting, reach a minimum, and then increase as `alpha` becomes very large and the model starts to underfit.\n",
    "    - Compared to Lasso, Ridge tends to shrink coefficients towards zero but doesn't usually set them exactly to zero unless alpha is extremely large. This means Ridge keeps all features in the model, but penalizes their magnitudes. The impact on RMSE curves might show a smoother U-shape for validation RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion of Lasso Performance vs. Alpha (Question 4.3)**\n",
    "\n",
    "The plot above shows the Root Mean Squared Error (RMSE) for the Lasso model on both the training and validation datasets as the shrinkage parameter `alpha` varies.\n",
    "\n",
    "*   **Estimating the Best Alpha Value:**\n",
    "    The \"best\" alpha value is typically found where the validation RMSE is at its minimum. Observing the plot, we look for the point on the 'Validation RMSE' line that is lowest. This point represents the best trade-off between bias and variance for the Lasso model on unseen data. *[The user will need to visually inspect their generated plot to specify the approximate alpha value here. For example, they might say: \"The validation RMSE appears to be lowest around an alpha of 0.1 to 1.\"]*\n",
    "\n",
    "*   **Comparison of Training and Validation Plots:**\n",
    "    - At very low `alpha` values (e.g., towards the left of the plot), both training and validation RMSE are relatively low. The model is complex and fits the training data well (low training RMSE). If the validation RMSE is also low and close to the training RMSE, the model generalizes well.\n",
    "    - As `alpha` increases, the training RMSE generally tends to increase. This is because stronger regularization (larger `alpha`) forces the model to become simpler, potentially underfitting the training data.\n",
    "    - The validation RMSE typically shows a U-shape (or part of it). Initially, it might decrease as `alpha` increases from very small values, if the model was initially overfitting. Then it reaches a minimum point (the optimal `alpha`). After this point, as `alpha` continues to increase, the model becomes too simple (high bias), and the validation RMSE starts to increase again due to underfitting.\n",
    "    - The gap between the training and validation RMSE can also be indicative. A large gap often suggests overfitting (model performs much better on training data than on validation data). Regularization aims to reduce this gap by improving generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outlier Discussion (Q1.2):**\n",
    "Looking at the scatter plot of 'GrLivArea' vs 'SalePrice', there appear to be a few data points with very large 'GrLivArea' that do not follow the general trend of increasing 'SalePrice'. Specifically, points with 'GrLivArea' greater than 4000 seem like potential outliers as their 'SalePrice' is not correspondingly high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Question 1.3: Removing outliers in the data for all GrLivArea greater than 4000 then check the scatter plot again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape before removing outliers: {train.shape}\")\n",
    "train = train[train['GrLivArea'] <= 4000]\n",
    "print(f\"Shape after removing outliers: {train.shape}\")\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.scatterplot(x=train['GrLivArea'], y=train['SalePrice'])\n",
    "plt.title('GrLivArea vs. SalePrice (Outliers Removed)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quesiont 2.1: Convert categorical variable into dummy variables using pandas get_dummies API\n",
    "\n",
    "Do not use sklearn.  In sklearn you would have to do the following:\n",
    "1. identify the category columns in the dataframe\n",
    "2. ceate a one-hot-encoder object\n",
    "3. one-hot-encode the category columns of the dataframe and put results in a new dataframe\n",
    "4. drop the category columns from the original dataframe to create a dataframe of the original numeric variables\n",
    "5. combine the new dataframe of one-hot-encoded variables with the numeric variable of the original dataframe\n",
    "\n",
    "<br><br>\n",
    "Do the following:\n",
    "1. Please one-hot-encode using pandas `get_dummies`.  With `get_dummies`you just use the data as the argument for `get_dummies` and assign the output to the same variable name. \n",
    "3. Present shape of data.  Use `shape` as was done above.  How many columns were added?\n",
    "4. Present counts of data type.  Use `dtypes` and `value_counts` as was done above.  How have the data types changed? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape before one-hot encoding: {train.shape}\")\n",
    "print(f\"Data types before one-hot encoding:\\n{train.dtypes.value_counts()}\")\n",
    "\n",
    "train = pd.get_dummies(train)\n",
    "\n",
    "print(f\"Shape after one-hot encoding: {train.shape}\")\n",
    "print(f\"Data types after one-hot encoding:\\n{train.dtypes.value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One-Hot Encoding Discussion (Q2.1):**\n",
    "After applying `pd.get_dummies()`, the number of columns increased significantly, from the original number to the new shape's column count. This is because each category in the original object/categorical columns was converted into a new binary (0 or 1) column. Consequently, the data types also changed: the 'object' type columns were replaced by 'uint8' (unsigned 8-bit integer) type columns, representing the one-hot encoded features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2.2: Impute missing data by the median of each column.\n",
    "1. Count the total number of nulls in the data\n",
    "2. Replace nulls with column medians\n",
    "3. Count the total number of nulls in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total nulls before imputation: {train.isnull().sum().sum()}\")\n",
    "\n",
    "train = train.fillna(train.median())\n",
    "\n",
    "print(f\"Total nulls after imputation: {train.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2.3: Generate train validation (test) split of 70/30\n",
    "1. Create the input variables `X` without 'SalePrice'\n",
    "2. Create the target variable `y` which is 'SalePrice'\n",
    "3. Do train-test split to split data into training and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = train.drop('SalePrice', axis=1)\n",
    "y = train['SalePrice']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3.1: Train a linear regression algorithm to predict `SalePrice` from the remaining features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "print(\"LinearRegression model trained.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3.2: Evaluate the model with RMSE. Report the performance on both training and test data. These numbers will serve as our benchmark performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Predict on training and validation sets\n",
    "y_train_pred_lr = lr_model.predict(X_train)\n",
    "y_test_pred_lr = lr_model.predict(X_test)  # Assuming X_test and y_test are from Q2.3\n",
    "\n",
    "# Calculate RMSE\n",
    "lr_rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred_lr))\n",
    "lr_rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred_lr))\n",
    "\n",
    "print(f\"Linear Regression RMSE on Training Data: {lr_rmse_train}\")\n",
    "print(f\"Linear Regression RMSE on Validation Data: {lr_rmse_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "We now train a regularized version of `LinearRegression` called `Lasso`. `Lasso` has an argument called `alpha`, which is the **shrinkage parameter**.\n",
    "\n",
    "Question 4.1: Let `alpha = 0.000001` and train a `Lasso` algorithm. Show that the resulting model is practically identical to the one we trained with `LinearRegression`. There are different ways to show this, so you will need to think of a way. <span style=\"color:red\" float:right>[2 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Initialize and train Lasso model\n",
    "lasso_model_q41 = Lasso(alpha=0.000001, max_iter=10000) # Added max_iter to help convergence with small alpha\n",
    "lasso_model_q41.fit(X_train, y_train)\n",
    "print(\"Lasso model (alpha=0.000001) trained.\")\n",
    "\n",
    "# Predict on training and validation sets\n",
    "y_train_pred_lasso_q41 = lasso_model_q41.predict(X_train)\n",
    "y_test_pred_lasso_q41 = lasso_model_q41.predict(X_test)\n",
    "\n",
    "# Calculate RMSE for Lasso model\n",
    "lasso_rmse_train_q41 = np.sqrt(mean_squared_error(y_train, y_train_pred_lasso_q41))\n",
    "lasso_rmse_test_q41 = np.sqrt(mean_squared_error(y_test, y_test_pred_lasso_q41))\n",
    "\n",
    "print(f\"Lasso (alpha=0.000001) RMSE on Training Data: {lasso_rmse_train_q41}\")\n",
    "print(f\"Lasso (alpha=0.000001) RMSE on Validation Data: {lasso_rmse_test_q41}\")\n",
    "\n",
    "print(\"\\n--- RMSE Comparison ---\")\n",
    "print(f\"Linear Regression RMSE (Train): {lr_rmse_train}\")\n",
    "print(f\"Lasso (alpha=0.000001) RMSE (Train): {lasso_rmse_train_q41}\")\n",
    "print(f\"Linear Regression RMSE (Validation): {lr_rmse_test}\")\n",
    "print(f\"Lasso (alpha=0.000001) RMSE (Validation): {lasso_rmse_test_q41}\")\n",
    "\n",
    "print(\"\\n--- Coefficient Comparison ---\")\n",
    "print(f\"First 5 coefficients of Linear Regression model: {lr_model.coef_[:5]}\")\n",
    "print(f\"First 5 coefficients of Lasso (alpha=0.000001) model: {lasso_model_q41.coef_[:5]}\")\n",
    "\n",
    "coef_diff = np.sum(np.abs(lr_model.coef_ - lasso_model_q41.coef_))\n",
    "print(f\"Sum of absolute differences in coefficients: {coef_diff}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparison of LinearRegression and Lasso (alpha=0.000001) Models**\n",
    "\n",
    "As shown by the RMSE scores, the Lasso model with a very small alpha (0.000001) performs almost identically to the LinearRegression model on both the training and validation datasets. \n",
    "The RMSE values are very close:\n",
    "- Training RMSE: LinearRegression (`lr_rmse_train`) vs. Lasso (`lasso_rmse_train_q41`)\n",
    "- Validation RMSE: LinearRegression (`lr_rmse_test`) vs. Lasso (`lasso_rmse_test_q41`)\n",
    "\n",
    "Furthermore, comparing the model coefficients reveals that they are also very similar. The sum of absolute differences between the coefficient vectors is very small (`coef_diff`). This indicates that with such a minimal shrinkage parameter, the L1 regularization in Lasso has a negligible effect, making the Lasso model behave like an ordinary least squares linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "Question 4.2: Iteratively train a new `Lasso` model, letting `alpha` change each time to one of the values given by the suggested `alpha_vals` below.\n",
    "For each alpha keep track of and store: \n",
    "- the performance (RMSE) on the training data\n",
    "- the performance (RMSE) on the validation (test) data\n",
    "- the coefficients (`coef_`) of the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_vals = 10**np.arange(-1, 4, .2)\n",
    "\n",
    "lasso_train_rmse_list = []\n",
    "lasso_test_rmse_list = []\n",
    "lasso_coefs_list = []\n",
    "\n",
    "from sklearn.linear_model import Lasso # Ensure Lasso is imported\n",
    "\n",
    "for alpha_val in alpha_vals:\n",
    "    # Initialize and train Lasso model\n",
    "    # Increased max_iter for better convergence, especially at small alphas\n",
    "    lasso_model_iter = Lasso(alpha=alpha_val, max_iter=10000, random_state=42) \n",
    "    lasso_model_iter.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on training and validation sets\n",
    "    y_train_pred_lasso_iter = lasso_model_iter.predict(X_train)\n",
    "    y_test_pred_lasso_iter = lasso_model_iter.predict(X_test)\n",
    "    \n",
    "    # Calculate RMSE\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred_lasso_iter))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred_lasso_iter))\n",
    "    \n",
    "    # Store results\n",
    "    lasso_train_rmse_list.append(train_rmse)\n",
    "    lasso_test_rmse_list.append(test_rmse)\n",
    "    lasso_coefs_list.append(lasso_model_iter.coef_)\n",
    "    \n",
    "print(\"Lasso iteration complete.\")\n",
    "print(f\"Number of alpha values tested: {len(alpha_vals)}\")\n",
    "print(f\"First training RMSE: {lasso_train_rmse_list[0]}\")\n",
    "print(f\"First validation RMSE: {lasso_test_rmse_list[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 4.3: Using a visual, show how the performance (rmse) on the training and test data changed as we gradually increased `alpha`. Use a lineplot where the x-axis is `alpha` and the y-axis is rmse.  Use a log scale for the x-axis.\n",
    "<br><br>\n",
    "Discuss your results:\n",
    "- From this plot, estimate the best alpha value.\n",
    "- How does the plot for the training data compare to the lineplot of the validation (test) data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns # Optional, but can make plots nicer\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(alpha_vals, lasso_train_rmse_list, label='Training RMSE', marker='o', linestyle='-')\n",
    "plt.plot(alpha_vals, lasso_test_rmse_list, label='Validation RMSE', marker='o', linestyle='-')\n",
    "\n",
    "plt.xscale('log') # Set x-axis to log scale\n",
    "plt.xlabel('Alpha (Shrinkage Parameter)')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Lasso Model Performance vs. Alpha')\n",
    "plt.legend()\n",
    "plt.grid(True, which=\"both\", ls=\"--\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 4.4: Using a visual, show how the model's coefficients changed as we gradually increased the shrinkage parameter `alpha`. HINT: They should appear to be shrinking toward zero as you increase `alpha`!  There are too many coefficients to create lineplots for every coefficient.  Present only a subset of the coefficients that make the point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd # For easier handling of coefficients\n",
    "%matplotlib inline\n",
    "\n",
    "# Convert list of coefficient arrays into a DataFrame\n",
    "# Assuming X_train.columns contains the feature names\n",
    "lasso_coefs_df = pd.DataFrame(lasso_coefs_list, index=alpha_vals, columns=X_train.columns)\n",
    "\n",
    "# Plotting a subset of coefficients (e.g., first 10)\n",
    "# Or, select coefficients that show interesting behavior (e.g., largest magnitude at low alpha)\n",
    "# For simplicity, let's plot the first 10. If X_train has fewer than 10 columns, it will plot all.\n",
    "num_coeffs_to_plot = min(10, len(X_train.columns))\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "for feature in lasso_coefs_df.columns[:num_coeffs_to_plot]:\n",
    "    plt.plot(lasso_coefs_df.index, lasso_coefs_df[feature], label=feature)\n",
    "\n",
    "plt.xscale('log') # Set x-axis to log scale\n",
    "plt.xlabel('Alpha (Shrinkage Parameter)')\n",
    "plt.ylabel('Coefficient Value')\n",
    "plt.title('Lasso Model Coefficients vs. Alpha (Subset)')\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5)) # Adjust legend to prevent overlap\n",
    "plt.grid(True, which=\"both\", ls=\"--\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Number of non-zero coefficients for different alphas:\")\n",
    "for alpha_val in [alpha_vals[0], alpha_vals[len(alpha_vals)//2], alpha_vals[-1]]:\n",
    "    num_nonzero = np.sum(lasso_coefs_df.loc[alpha_val] != 0)\n",
    "    print(f\"Alpha = {alpha_val:.2f}: {num_nonzero} non-zero coefficients\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion of Lasso Coefficients vs. Alpha (Question 4.4)**\n",
    "\n",
    "The plot above illustrates how the magnitudes of the Lasso model's coefficients change as the shrinkage parameter `alpha` increases. A subset of the coefficients is shown for clarity.\n",
    "\n",
    "*   **Shrinkage Towards Zero:**\n",
    "    As `alpha` increases, the L1 regularization penalty becomes more significant. This forces many of the coefficients towards zero. This is a key characteristic of Lasso regression, which performs feature selection by effectively eliminating less important features (i.e., setting their coefficients to zero).\n",
    "\n",
    "*   **Feature Selection:**\n",
    "    You can observe that some coefficients shrink to zero faster than others. Coefficients that remain non-zero for higher values of `alpha` are generally considered more important by the model. At very high `alpha` values, most or all coefficients might be shrunk to zero, resulting in a very simple model. The printout above also shows how the count of non-zero coefficients changes with alpha, typically decreasing as alpha increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 5.1: Repeat steps in Question 4.2.  This time using `Ridge` instead of `Lasso`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_train_rmse_list = []\n",
    "ridge_test_rmse_list = []\n",
    "ridge_coefs_list = []\n",
    "\n",
    "from sklearn.linear_model import Ridge # Ensure Ridge is imported\n",
    "\n",
    "for alpha_val in alpha_vals:\n",
    "    # Initialize and train Ridge model\n",
    "    ridge_model_iter = Ridge(alpha=alpha_val, random_state=42) \n",
    "    ridge_model_iter.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on training and validation sets\n",
    "    y_train_pred_ridge_iter = ridge_model_iter.predict(X_train)\n",
    "    y_test_pred_ridge_iter = ridge_model_iter.predict(X_test)\n",
    "    \n",
    "    # Calculate RMSE\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred_ridge_iter))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred_ridge_iter))\n",
    "    \n",
    "    # Store results\n",
    "    ridge_train_rmse_list.append(train_rmse)\n",
    "    ridge_test_rmse_list.append(test_rmse)\n",
    "    ridge_coefs_list.append(ridge_model_iter.coef_)\n",
    "    \n",
    "print(\"Ridge iteration complete.\")\n",
    "print(f\"Number of alpha values tested: {len(alpha_vals)}\")\n",
    "print(f\"First training RMSE (Ridge): {ridge_train_rmse_list[0]}\")\n",
    "print(f\"First validation RMSE (Ridge): {ridge_test_rmse_list[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 5.2: Using a visual, show how the performance (rmse) on the training and test data changed as we gradually increased `alpha`. Use a lineplot where the x-axis is `alpha` and the y-axis is rmse.  Use a log scale for the x-axis.  \n",
    "<br><br>\n",
    "Discuss your results:\n",
    "- From this plot, estimate the best alpha value.\n",
    "- How does the plot for the training data compare to the validation (test) data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(alpha_vals, ridge_train_rmse_list, label='Training RMSE (Ridge)', marker='o', linestyle='-')\n",
    "plt.plot(alpha_vals, ridge_test_rmse_list, label='Validation RMSE (Ridge)', marker='o', linestyle='-')\n",
    "\n",
    "plt.xscale('log') # Set x-axis to log scale\n",
    "plt.xlabel('Alpha (Shrinkage Parameter)')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Ridge Model Performance vs. Alpha')\n",
    "plt.legend()\n",
    "plt.grid(True, which=\"both\", ls=\"--\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 5.3: Using a visual, show how the model's coefficients changed as we gradually increased the shrinkage parameter `alpha`. HINT: They should appear to be shrinking toward zero as you increase `alpha`!  There are too many coefficients to create lineplots for every coefficient.  Present a subset of the coefficients that make the point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd # For easier handling of coefficients\n",
    "%matplotlib inline\n",
    "\n",
    "# Convert list of coefficient arrays into a DataFrame\n",
    "# Assuming X_train.columns contains the feature names\n",
    "ridge_coefs_df = pd.DataFrame(ridge_coefs_list, index=alpha_vals, columns=X_train.columns)\n",
    "\n",
    "# Plotting a subset of coefficients (e.g., first 10)\n",
    "num_coeffs_to_plot = min(10, len(X_train.columns))\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "for feature in ridge_coefs_df.columns[:num_coeffs_to_plot]:\n",
    "    plt.plot(ridge_coefs_df.index, ridge_coefs_df[feature], label=feature)\n",
    "\n",
    "plt.xscale('log') # Set x-axis to log scale\n",
    "plt.xlabel('Alpha (Shrinkage Parameter)')\n",
    "plt.ylabel('Coefficient Value')\n",
    "plt.title('Ridge Model Coefficients vs. Alpha (Subset)')\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5)) # Adjust legend\n",
    "plt.grid(True, which=\"both\", ls=\"--\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion of Ridge Coefficients vs. Alpha (Question 5.3)**\n",
    "\n",
    "The plot above illustrates how the magnitudes of the Ridge model's coefficients change as the shrinkage parameter `alpha` increases. A subset of coefficients is shown.\n",
    "\n",
    "*   **Shrinkage Towards Zero (but not exactly zero):**\n",
    "    As `alpha` increases, the L2 regularization penalty in Ridge regression also becomes more significant. This forces the coefficients towards zero, but unlike Lasso, Ridge typically does not shrink coefficients *exactly* to zero unless alpha is infinitely large. Instead, coefficients are reduced in magnitude, helping to prevent overfitting by reducing model complexity.\n",
    "\n",
    "*   **Behavior Compared to Lasso:**\n",
    "    Comparing this plot to the Lasso coefficient plot (Q4.4), you'll notice that while Lasso drives many coefficients to absolute zero (performing feature selection), Ridge tends to shrink all coefficients more smoothly and proportionally. All features are typically retained by Ridge, but their influence is moderated by the regularization. This often results in a dense model (many non-zero, albeit small, coefficients) as opposed to Lasso's sparse models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code can be removed\n",
    "print(\"Elapsed time: \", time.time() - start_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
